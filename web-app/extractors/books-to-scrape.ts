/**
 * Books to Scrape Extractor
 * Auto-generated by Manus on 2026-01-31
 *
 * Usage:
 *   import { extract } from './books-to-scrape';
 *   const data = await extract(page);
 */
import type { Page } from 'playwright';

export interface BooksToScrapeData {
  title: string;
  price: string;
}

export const config = {
  name: 'Books to Scrape',
  urlPattern: /books.toscrape.com/,
  selectors: {
    container: 'article.product_pod',
    title: 'h3 a',
    price: 'p.price_color',
  },
};

/**
 * Extract data from the page
 */
export async function extract(page: Page): Promise<BooksToScrapeData[]> {
  const items = await page.$$(config.selectors.container);

  const data: BooksToScrapeData[] = [];
  for (const item of items) {
    try {
      data.push({
      title: await item.$eval('h3 a', el => el.textContent?.trim() ?? ''),
      price: await item.$eval('p.price_color', el => el.textContent?.trim() ?? ''),
      });
    } catch (error) {
      console.warn('Failed to extract item:', error);
    }
  }

  return data;
}

/**
 * Check if a URL matches this extractor's pattern
 */
export function matches(url: string): boolean {
  return config.urlPattern.test(url);
}

/**
 * Validate extracted data
 */
export function validate(data: BooksToScrapeData[]): { valid: boolean; issues: string[] } {
  const issues: string[] = [];

  if (data.length === 0) {
    issues.push('No data extracted');
  }

  data.forEach((item, index) => {
    const emptyFields = Object.entries(item)
      .filter(([_, value]) => !value || String(value).trim() === '')
      .map(([key]) => key);

    if (emptyFields.length > 0) {
      issues.push(`Row ${index + 1}: empty fields - ${emptyFields.join(', ')}`);
    }
  });

  return {
    valid: issues.length === 0,
    issues,
  };
}
