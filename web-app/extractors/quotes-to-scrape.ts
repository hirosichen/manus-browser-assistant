/**
 * Quotes to Scrape Extractor
 * Auto-generated by Manus on 2026-01-31
 *
 * Usage:
 *   import { extract } from './quotes-to-scrape';
 *   const data = await extract(page);
 */
import type { Page } from 'playwright';

export interface QuotesToScrapeData {
  content: string;
  author: string;
}

export const config = {
  name: 'Quotes to Scrape',
  urlPattern: /quotes.toscrape.com/,
  selectors: {
    container: '.quote',
    content: '.text',
    author: '.author',
  },
};

/**
 * Extract data from the page
 */
export async function extract(page: Page): Promise<QuotesToScrapeData[]> {
  const items = await page.$$(config.selectors.container);

  const data: QuotesToScrapeData[] = [];
  for (const item of items) {
    try {
      data.push({
      content: await item.$eval('.text', el => el.textContent?.trim() ?? ''),
      author: await item.$eval('.author', el => el.textContent?.trim() ?? ''),
      });
    } catch (error) {
      console.warn('Failed to extract item:', error);
    }
  }

  return data;
}

/**
 * Check if a URL matches this extractor's pattern
 */
export function matches(url: string): boolean {
  return config.urlPattern.test(url);
}

/**
 * Validate extracted data
 */
export function validate(data: QuotesToScrapeData[]): { valid: boolean; issues: string[] } {
  const issues: string[] = [];

  if (data.length === 0) {
    issues.push('No data extracted');
  }

  data.forEach((item, index) => {
    const emptyFields = Object.entries(item)
      .filter(([_, value]) => !value || String(value).trim() === '')
      .map(([key]) => key);

    if (emptyFields.length > 0) {
      issues.push(`Row ${index + 1}: empty fields - ${emptyFields.join(', ')}`);
    }
  });

  return {
    valid: issues.length === 0,
    issues,
  };
}
